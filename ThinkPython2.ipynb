{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_triangle(a,b,c):\n",
    "    \"\"\"is_triangle takes three numbers as input. Creates a list of these integers which is then sorted.\n",
    "    If the sum of the two smallest numbers is >= to the largest number then it is a triangle. \n",
    "    \"\"\"\n",
    "    lengths =[a,b,c] # create a list of the lengths\n",
    "    lengths.sort() #order the side lengths\n",
    "    if lengths[0] + lengths[1] >= lengths[2]:\n",
    "        return 'Y'\n",
    "    else:\n",
    "        return 'N'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_triangle(1.1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fibonacci(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci(n-1) + fibonacci(n-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17711"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fibonacci(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(2.0,int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the Moby collection, the filename is 113809of.fic; you can download a copywith the simpler name words.txt, \n",
    "# from http://thinkpython2.com/code/words.txt.\n",
    "\n",
    "\n",
    "fin = open('words.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffaa\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counterdemonstrations 21\n",
      "hyperaggressivenesses 21\n",
      "microminiaturizations 21\n"
     ]
    }
   ],
   "source": [
    "for line in fin:\n",
    "    word = line.strip()\n",
    "    if len(word) > 20:\n",
    "        print(word + ' '+str(len(word)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_out = []\n",
    "for line in fin:\n",
    "    word = line.strip()\n",
    "    list_out.extend(list(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def histogram(s):\n",
    "    d = dict()\n",
    "    for c in s:\n",
    "        if c not in d:\n",
    "            d[c] = 1\n",
    "        else:\n",
    "            d[c] += 1\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# histogram of words\n",
    "\n",
    "histogram(list(fin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 68582,\n",
       " 'b': 17798,\n",
       " 'c': 34287,\n",
       " 'd': 34552,\n",
       " 'e': 106758,\n",
       " 'f': 12714,\n",
       " 'g': 27848,\n",
       " 'h': 20200,\n",
       " 'i': 77412,\n",
       " 'j': 1780,\n",
       " 'k': 9370,\n",
       " 'l': 47011,\n",
       " 'm': 24741,\n",
       " 'n': 60513,\n",
       " 'o': 54542,\n",
       " 'p': 25789,\n",
       " 'q': 1632,\n",
       " 'r': 64965,\n",
       " 's': 86547,\n",
       " 't': 57059,\n",
       " 'u': 31161,\n",
       " 'v': 9186,\n",
       " 'w': 8535,\n",
       " 'x': 2700,\n",
       " 'y': 13473,\n",
       " 'z': 3750,\n",
       " '\\ufeff': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# histogram of letters\n",
    "\n",
    "fin = open('words.txt')\n",
    "list_out = []\n",
    "for line in fin:\n",
    "    word = line.strip()\n",
    "    list_out.extend(list(word))\n",
    "    blah = list(word)\n",
    "\n",
    "histogram(list_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 'a', 'b', 'c', 'd', 'e'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 'b', 'c', 'd', 'e')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this returns a tuple and is a beautiful funciton\n",
    "divmod(7,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "def process_file(filename, skip_header):\n",
    "    \"\"\"Makes a histogram that contains the words from a file.\n",
    "\n",
    "    filename: string\n",
    "    skip_header: boolean, whether to skip the Gutenberg header\n",
    "   \n",
    "    returns: map from each word to the number of times it appears.\n",
    "    \"\"\"\n",
    "    hist = {}\n",
    "    fp = open(filename)\n",
    "\n",
    "    if skip_header:\n",
    "        skip_gutenberg_header(fp)\n",
    "\n",
    "    for line in fp:\n",
    "        process_line(line, hist)\n",
    "\n",
    "    return hist\n",
    "\n",
    "\n",
    "def skip_gutenberg_header(fp):\n",
    "    \"\"\"Reads from fp until it finds the line that ends the header.\n",
    "\n",
    "    fp: open file object\n",
    "    \"\"\"\n",
    "    for line in fp:\n",
    "        #if line.startswith('*END*THE SMALL PRINT!'):\n",
    "        if line.startswith('*** START OF THIS PROJECT'):\n",
    "            break\n",
    "\n",
    "\n",
    "def process_line(line, hist):\n",
    "    \"\"\"Adds the words in the line to the histogram.\n",
    "\n",
    "    Modifies hist.\n",
    "\n",
    "    line: string\n",
    "    hist: histogram (map from word to frequency)\n",
    "    \"\"\"\n",
    "    # TODO: rewrite using Counter\n",
    "\n",
    "    # replace hyphens with spaces before splitting\n",
    "    line = line.replace('-', ' ')\n",
    "    strippables = string.punctuation + string.whitespace\n",
    "\n",
    "    for word in line.split():\n",
    "        # remove punctuation and convert to lowercase\n",
    "        word = word.strip(strippables)\n",
    "        word = word.lower()\n",
    "\n",
    "        # update the histogram\n",
    "        hist[word] = hist.get(word, 0) + 1\n",
    "\n",
    "\n",
    "def most_common(hist):\n",
    "    \"\"\"Makes a list of word-freq pairs in descending order of frequency.\n",
    "\n",
    "    hist: map from word to frequency\n",
    "\n",
    "    returns: list of (frequency, word) pairs\n",
    "    \"\"\"\n",
    "    t = []\n",
    "    for key, value in hist.items():\n",
    "        t.append((value, key))\n",
    "\n",
    "    t.sort()\n",
    "    t.reverse()\n",
    "    return t\n",
    "\n",
    "\n",
    "def print_most_common(hist, num=10):\n",
    "    \"\"\"Prints the most commons words in a histgram and their frequencies.\n",
    "    \n",
    "    hist: histogram (map from word to frequency)\n",
    "    num: number of words to print\n",
    "    \"\"\"\n",
    "    t = most_common(hist)\n",
    "    print('The most common words are:')\n",
    "    for freq, word in t[:num]:\n",
    "        print(word, '\\t', freq)\n",
    "\n",
    "\n",
    "def subtract(d1, d2):\n",
    "    \"\"\"Returns a dictionary with all keys that appear in d1 but not d2.\n",
    "\n",
    "    d1, d2: dictionaries\n",
    "    \"\"\"\n",
    "    # TODO: reimplement using Counter\n",
    "    res = {}\n",
    "    for key in d1:\n",
    "        if key not in d2:\n",
    "            res[key] = None\n",
    "    return res\n",
    "\n",
    "\n",
    "def total_words(hist):\n",
    "    \"\"\"Returns the total of the frequencies in a histogram.\"\"\"\n",
    "    return sum(hist.values())\n",
    "\n",
    "\n",
    "def different_words(hist):\n",
    "    \"\"\"Returns the number of different words in a histogram.\"\"\"\n",
    "    return len(hist)\n",
    "\n",
    "\n",
    "def random_word(hist):\n",
    "    \"\"\"Chooses a random word from a histogram.\n",
    "\n",
    "    The probability of each word is proportional to its frequency.\n",
    "    \"\"\"\n",
    "    # TODO: rewrite using Counter\n",
    "    t = []\n",
    "    for word, freq in hist.items():\n",
    "        t.extend([word] * freq)\n",
    "\n",
    "    return random.choice(t)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 29909\n",
      "Number of different words: 4026\n",
      "The most common words are:\n",
      "the \t 1795\n",
      "and \t 884\n",
      "to \t 799\n",
      "a \t 678\n",
      "of \t 616\n",
      "she \t 536\n",
      "it \t 467\n",
      "said \t 461\n",
      "in \t 419\n",
      "alice \t 384\n",
      "you \t 372\n",
      "was \t 352\n",
      "i \t 273\n",
      "as \t 266\n",
      "that \t 254\n",
      "her \t 247\n",
      "at \t 223\n",
      "with \t 222\n",
      "on \t 192\n",
      "all \t 188\n",
      "The words in the book that aren't in the word list are:\n",
      "﻿project gutenberg’s alice’s carroll ebook gutenberg online www.gutenberg.org june 25 2008 11 1994 october 6 2016 utf 8  3.0 i alice ‘and a book,’ ‘without conversations?’ ‘oh late!’ waistcoat ‘orange marmalade’ ‘well!’ ‘after they’ll wouldn’t house!’ ‘i i’ve time?’ ’ ‘ that’s to?’ it’ll didn’t ma’am zealand australia?’ you’re she’ll somewhere.’ ‘dinah’ll think!’ dinah i’m wonder?’ ‘do bats?’ cats?’ couldn’t ‘now bat?’ it’s getting!’ through,’ ‘it begin.’ ‘which before,’ ‘drink me’ me,’ ‘no i’ll first,’ “poison” not’ ‘poison,’ ‘what feeling!’ telescope.’ ‘for know,’ ‘in then?’ ‘come there’s that!’ minute!’ ‘but now,’ ‘to person!’ ‘eat ‘well it,’ don’t happens!’ way?’ ii ‘curiouser curiouser!’ feet!’ shan’t them,’ ‘or won’t christmas.’ ‘they carrier,’ one’s esq hearthrug talking!’ ‘you yourself,’ ‘a you,’ you!’ waiting!’ ‘if skurried ‘dear puzzle!’ ‘i’m ada,’ doesn’t can’t mabel she’s let’s london rome “how “’ ‘how nile jaws!’ words,’ “come dear!” “who else” dear!’ here!’ rabbit’s that?’ again.’ ‘that escape!’ garden!’ ever,’ is!’ railway,’ hadn’t much!’ day.’ ‘would trying.’ ‘o o mouse!’ brother’s latin ‘perhaps english,’ william conqueror.’ ‘ou est chatte?’ pardon!’ animal’s cats.’ ‘not cats!’ me?’ not,’ ‘don’t you’d thing,’ ‘we not.’ indeed!’ ‘as again!’ ‘are dogs?’ ‘there ‘mouse them!’ ‘let you’ll dogs.’ iii better’ ‘sit enough!’ ‘ahem!’ “william usurpation edwin morcar mercia northumbria ‘ugh!’ ‘did speak?’ i!’ did,’ “edwin stigand canterbury ‘found what?’ ‘of “it” means.’ ‘it’s find?’ hurriedly ‘“ edgar william’s normans ” dear?’ all.’ case,’ ‘speak english!’ what’s either!’ say,’ ‘was race.’ race?’ ‘why,’ ‘the it.’ matter,’ ‘one away,’ over!’ won?’ shakespeare ‘everybody prizes.’ prizes?’ ‘why course,’ ‘prizes prizes!’ pocket?’ ‘only thimble,’ ‘hand here,’ thimble’ c d,’ ‘mine tale!’ certainly,’ mouse’s sad?’ ‘fury “let do.” “such breath.” “i’ll jury,” death.”’ attending!’ of?’ pardon,’ think?’ not!’ knot!’ it!’ sort,’ nonsense!’ know!’ ‘please story!’ ‘yes do!’ stay!’ ‘ah temper!’ ‘hold ma!’ snappishly ‘you’re oyster!’ ‘she’d back!’ question?’ ‘dinah’s throat!’ bed!’ dinah!’ ‘nobody more!’ iv naturedly mary ann now!’ ‘he housemaid,’ he’ll i’d them.’ ‘w rabbit’ seems,’ dinah’ll next!’ ‘“miss walk!” “coming out.” think,’ they’d happen,’ ‘whenever thing!’ ‘that’s home,’ ‘when wasn’t ‘at here.’ then,’ ‘shall that’ll shouldn’t alice!’ books!’ ‘mary ann!’ ‘fetch moment!’ ‘then window.’ won’t’ ‘pat you?’ ‘sure yer honour!’ ‘digging ‘here this!’ window?’ ‘arrum.’ ‘an window!’ that.’ away!’ all!’ coward!’ be!’ longer!’ cartwheels ‘where’s bill’s ‘em below!’ who’s chimney!’ he?’ ‘shy little!’ ‘this bill,’ bill!’ ‘catch hedge!’ rocket!’ ‘so fellow!’ down!’ off.’ barrowful with.’ ‘i’ll this,’ ‘you’d cakes,’ suppose.’ do,’ ‘is plan.’ ‘poor puppy’s was!’ v ‘who then.’ ‘explain yourself!’ sir’ ‘because see.’ see,’ clearly,’ confusing.’ isn’t,’ haven’t yet,’ bit,’ different,’ ‘all me.’ ‘you!’ caterpillar’s first.’ ‘why?’ ‘i’ve say!’ ‘keep temper,’ all?’ ‘no,’ sir,’ together!’ ‘can’t things?’ bee,” different!’ ‘repeat “you william,”’ william,’ right?’ youth,’ old,’ couple?’ it?’ life.’ clever?’ enough,’ stairs!’ right,’ afraid,’ ‘some altered.’ end,’ be?’ size,’ know.’ now?’ mind,’ ‘three be.’ offended!’ ‘you’ll time,’ shorter.’ mushroom,’ which?’ lefthand head’s last!’ ‘serpent!’ serpent!’ alone!’ ‘serpent about,’ hedges,’ eggs,’ weeks!’ you’ve annoyed,’ wood,’ something!’ girl,’ egg!’ they’re say.’ serpent?’ raw.’ then!’ ‘whoever there,’ ‘it’ll wits!’ righthand vi croquet.’ ‘from ‘there’s knocking,’ you.’ in?’ ‘his ‘till footman’s maybe,’ dreadful,’ crazy!’ ‘on days.’ do?’ ‘anything like,’ him,’ ‘he’s idiotic!’ soup!’ alternately moment’s cheshire cat,’ pig!’ grin.’ can,’ do.’ much,’ fact.’ doing!’ nose’ unusually business,’ does.’ advantage,’ ‘just ‘talking axes,’ ‘chop head!’ ‘twenty figures!’ teases.’ ‘wow wow!’ pleases!’ like!’ queen,’ fish,’ ‘they’re behind?’ grunt,’ yourself.’ sobbing,’ dear,’ home?’ up,’ think.’ ‘cheshire puss,’ far,’ here?’ to,’ go,’ somewhere,’ that,’ enough.’ direction,’ ‘lives mad.’ people,’ ‘we’re mad?’ be,’ with,’ dog’s so,’ growling,’ ‘call day?’ yet.’ ‘by baby?’ ‘i’d ask.’ pig,’ would,’ march.’ fig?’ giddy.’ grin,’ life!’ ‘suppose instead!’ vii ‘very dormouse,’ mind.’ room!’ ‘have wine,’ isn’t any,’ invited,’ table,’ three.’ ‘your cutting,’ remarks,’ rude.’ desk?’ they’ve ‘exactly mean,’ bit!’ “i eat” see”!’ get” like”!’ sleep” breathe”!’ fourth.’ ‘two wrong!’ works!’ butter,’ well,’ knife.’ watch!’ o’clock ‘does is?’ together.’ mine,’ hatter’s again,’ myself.’ yet?’ ‘what’s answer?’ idea,’ ‘nor i,’ ‘than answers.’ him.’ don’t!’ time!’ music.’ he’d dinner!’ was,’ perhaps,’ liked.’ manage?’ “twinkle at!” perhaps?’ “up ‘twinkle verse,’ “he’s head!”’ savage!’ now.’ we’ve whiles.’ suppose?’ up.’ again?’ subject,’ story.’ one,’ shall!’ ‘wake dormouse!’ asleep,’ saying.’ ‘tell done.’ ‘once sisters,’ elsie lacie tillie on?’ treacle,’ ‘they’d ill.’ were,’ well?’ ‘take tea,’ more.’ less,’ nothing.’ opinion,’ ‘who’s well.’ ‘sh sh!’ on!’ one.’ draw?’ ‘treacle,’ cup,’ ‘let’s on.’ dormouse’s from?’ stupid?’ were’ in.’ draw,’ m m?’ not?’ “much muchness” muchness?’ ‘really talk,’ curious!’ everything’s once.’ viii queen’s ‘look ‘seven elbow.’ others!’ talk!’ beheaded!’ for?’ two!’ business!’ onions.’ roses?’ we’re queen!’ recognised king’s procession,’ this?’ ‘idiot!’ child?’ ‘my majesty,’ needn’t these?’ rosetree know?’ mine.’ ‘off ‘nonsense!’ ‘consider child!’ ‘turn ‘get up!’ ‘leave ‘may see!’ heads!’ off?’ ‘their majesty!’ right!’ ‘can croquet?’ ‘yes!’ day!’ ‘very,’ where’s duchess?’ ‘hush hush!’ ‘she’s execution.’ “what pity!”?’ didn’t,’ for?”’ ‘she places!’ alive!’ to.’ fairly,’ coming!’ queen?’ all,’ game.’ cat’s ‘allow ‘however likes.’ impertinent,’ king,’ where.’ removed,’ removed!’ myself,’ ground.’ executioner’s weren’t she’d prison,’ ix turtle’s duchess,’ tempered,’ bit.’ hasn’t ‘tut ‘everything’s game’s ‘’tis “oh ‘tis round!”’ ‘somebody said,’ “take themselves.”’ things!’ waist,’ experiment?’ bite,’ true,’ ‘flamingoes “birds together.”’ bird,’ ‘right usual,’ is,’ “the yours.”’ is.’ “be be” “never otherwise.”’ better,’ chose,’ ‘pray trouble!’ present!’ ‘thinking duchess’s favourite ‘moral,’ warning,’ ‘either choice!’ game,’ from,’ history,’ pardoned.’ ‘up ordered’ fun!’ fun?’ she,’ on!” never!’ sorrow?’ lady,’ her,’ finished.’ ‘once,’ turtle.’ ‘hjckrrh!’ ‘thank story,’ little,’ one?’ us,’ dull!’ question,’ ‘drive mayn’t didn’t!’ tongue!’ too,’ ‘with extras?’ ‘yes,’ washing?’ ‘certainly school,’ “french extra.”’ ‘living sea.’ course.’ ‘reeling uglification derision.’ “uglification,”’ uglifying!’ prettier.’ simpleton.’ learn?’ mystery,’ seaography coils.’ like?’ ‘hadn’t was.’ lessons?’ ‘ten day,’ ‘nine plan!’ lessons,’ holiday?’ twelfth?’ x ‘same throat,’ haven’t,’ never’ delightful indeed,’ lines!’ ‘seals ‘each partner!’ ‘advance order,’ lobsters!’ ‘swim sea!’ ‘change ‘back figure,’ dance,’ figure!’ sing?’ sing,’ words.’ ‘“will faster?” “there’s he’s sea!” “too far!” ‘“what go?” “there england france dance?”’ watch,’ whiting!’ whiting,’ course?’ dinn like.’ crumbs.’ crumbs,’ ‘crumbs before.’ whiting?’ shoes.’ shoes!’ with?’ shiny?’ believe.’ ‘boots sea,’ ‘soles ‘any “keep us!”’ porpoise.’ ‘wouldn’t really?’ “with porpoise?”’ “purpose”?’ adventures.’ morning,’ ‘explanations time.’ curious.’ ‘stand “‘tis sluggard,”’ lessons!’ hair.” toes.’ child,’ nonsense.’ explained,’ ‘go verse.’ toes?’ dancing.’ garden.”’ stuff,’ heard!’ off,’ quadrille?’ song?’ kind,’ ‘hm “turtle soup,” fellow?’ ‘beautiful ootiful soo oop e pennyworth beauti ful ‘chorus trial’s beginning!’ ‘soo done,’ refreshments!’ judge,’ wig.’ box,’ creatures,’ ‘creatures,’ jurors.’ ‘jury men’ doing?’ begun.’ names,’ trial.’ ‘stupid ‘silence court!’ ‘stupid,’ neighbour slates’ll ‘herald accusation!’ verdict,’ yet!’ witness,’ ‘first witness!’ for.’ finished,’ begin?’ ‘fourteenth ‘fifteenth,’ ‘sixteenth,’ ‘write down,’ hat,’ ‘stolen!’ sell,’ hatter.’ ‘give evidence,’ spot.’ so.’ breathe.’ growing.’ ‘you’ve nonsense,’ too.’ pace,’ fashion.’ ‘bring concert!’ t!’ man,’ did!’ part.’ say?’ remember,’ executed.’ speaker,’ court,” lower,’ pigs!’ better.’ outside,’ ‘shan’t,’ witness.’ must,’ ‘pepper mostly,’ ‘collar ‘behead whiskers!’ ‘never mind!’ ache!’ ‘alice!’ xii ‘here!’ proceed,’ ‘until other.’ business?’ ‘nothing,’ ‘nothing whatever?’ whatever,’ important,’ ‘unimportant meant,’ ‘important ‘important,’ ‘unimportant.’ ‘silence!’ ‘rule court.’ high,’ are,’ ‘nearly rate,’ ‘besides somebody.’ ‘unless outside.’ verses.’ prisoner’s handwriting?’ else’s hand,’ end.’ man.’ guilt,’ sort!’ about!’ ‘read ‘where majesty?’ ‘begin beginning,’ stop.’ “ ‘“we “they you,”’ are!’ “before ‘never!’ pun!’ no!’ ‘sentence afterwards.’ ‘stuff first!’ won’t!’ cards!’ had!’ dream!’ late.’ sister’s neighbouring lizard’s 0.txt 0.zip http://www.gutenberg.org/1/11 tm ebooks redistribution “project gutenberg” http://gutenberg.org/license 1 1.a trademark/copyright 1.e.8 1.b 1.c 1.e foundation” pglaf 1.d downloading 1.e.1 1.e.2 1.e.7 1.e.9 1.e.3 1.e.4 1.e.5 1.e.6 nonproprietary hypertext “plain ascii” 20 60 4 “information foundation.” 30 s/he 1.f.3 90 michael 3 1.f 1.f.1 “defects,” 1.f.2 disclaimer “right refund” f3 electronically 1.f.4 is’ merchantibility 1.f.5 disclaimers unenforceability 1.f.6 b 2 tm’s 2001 http://www.pglaf.org non 501(c)(3 mississippi foundation’s ein 64 6221541 http://pglaf.org/fundraising u.s state’s 4557 melan dr s fairbanks ak 99712 809 1500 84116 801 596 1887 email business@pglaf.org http://pglaf.org gregory newby gbnewby@pglaf.org 5,000 irs charitable 50 http://pglaf.org/donate 5 pg http://www.gutenberg.org \n",
      "\n",
      "Here are some random words from the book\n",
      "to doing the began other rush with up,’ she and not worried rudeness ‘i jury it hurried that high,’ the in and very and round the lake i to talking last considerable you what moment to silence always very with thought mine see little at about and corner ‘then heard with ridge right ready law i there snail stop alice had she or please to she with away this next as the the dormouse got in of in a replied how it replied to again in if perhaps ‘she you agreement whatever and the went go leaning as in course "
     ]
    }
   ],
   "source": [
    "#hist = process_file('AliceInWonderland.txt', skip_header=True)\n",
    "hist = process_file('AliceInWonderland.txt', skip_header=False)\n",
    "print('Total number of words:', total_words(hist))\n",
    "print('Number of different words:', different_words(hist))\n",
    "\n",
    "t = most_common(hist)\n",
    "print('The most common words are:')\n",
    "for freq, word in t[0:20]:\n",
    "    print(word, '\\t', freq)\n",
    "\n",
    "words = process_file('words.txt', skip_header=False)\n",
    "\n",
    "diff = subtract(hist, words)\n",
    "print(\"The words in the book that aren't in the word list are:\")\n",
    "for word in diff.keys():\n",
    "    print(word, end=' ')\n",
    "\n",
    "print(\"\\n\\nHere are some random words from the book\")\n",
    "for i in range(100):\n",
    "    print(random_word(hist), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Walking directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def walk(dirname):\n",
    "    for name in os.listdir(dirname):\n",
    "        path = os.path.join(dirname, name)\n",
    "        if os.path.isfile(path):\n",
    "            print(path)\n",
    "        else:\n",
    "            walk(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/arb/Downloads/kaggle-talkingdata-visualization-master'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ffe93eb46803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/arb/Downloads/kaggle-talkingdata-visualization-master'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-25aa3a4442b7>\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(dirname)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/arb/Downloads/kaggle-talkingdata-visualization-master'"
     ]
    }
   ],
   "source": [
    "walk('/home/arb/Downloads/kaggle-talkingdata-visualization-master')\n",
    "os.walk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
